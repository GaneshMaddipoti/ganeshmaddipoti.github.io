{"id":null,"name":"Apache-Spark","data":{"id":"root","size":{"width":1571,"height":905},"pan":{"x":1286.7971815411827,"y":722.4248891131756,"scale":2.477018809551099},"children":[{"id":"node-1768386812421","position":{"x":1354.2491455078125,"y":764.10498046875},"size":{"width":458.478515625,"height":300},"type":"Container","title":"Apache Spark","description":"Apache Spark is a unified analytics engine for large-scale data processing. (Cluster computing platform)\nAt its core, Spark is a “computational engine” that is responsible for scheduling, distributing, and monitoring applications consisting of many computational tasks across many worker machines, or a computing cluster. \nIf Hadoop MapReduce was the \"first generation\" of big data processing, Spark is the \"second generation\"—built for speed, ease of use, and versatility.\n\nFeatures\nEasy to use: we can develop applications, using a high-level API that let us focus on the content of our computation\nSpeed: It is up to 100x faster than Hadoop MapReduce because it processes data in-memory (RAM) rather than writing to the disk after every step.\nLazy Evaluation: Spark doesn't execute your code immediately. It builds a plan (called a DAG or Directed Acyclic Graph) and only runs it when you finally ask for a result. This allows it to optimize the entire process first.\nAs general engine: letting you combine multiple types of computations (e.g., SQL queries, text process‐ing, and machine learning) that might previously have required different engines.\n\nPolyglot: You can write Spark code in Python (PySpark), Scala, Java, or R.\n\n\n\n\n\n\n\n","pan":{"x":-460.84062555276887,"y":-319.4435672790166,"scale":0.27835478184371387},"children":[{"id":"node-1768387001355","position":{"x":-149.17035293579102,"y":-287.57633113861084},"size":{"width":861.72607421875,"height":356.93047600984573},"type":"Container","title":"Architecture","description":"Spark operates on a Master-Slave architecture. It doesn't usually store data itself; instead, it reaches out to data sources (like S3 or HDFS), pulls the data into memory, and processes it across a cluster of computers.","pan":{"x":-752.4942311949649,"y":-320.2812295443693,"scale":0.3027063970070796},"children":[{"id":"node-1768387053759","position":{"x":-868.4981689453125,"y":-18.51860809326172},"size":{"width":565.7882995605469,"height":367.23626708984375},"type":"Container","title":"Driver","description":"Driver Program: The \"brain\" of your application. It runs your main() function and converts your code into tasks."},{"id":"node-1768387067534","position":{"x":-78.00450134277344,"y":-70.75757789611816},"size":{"width":1008.8296508789062,"height":503.1063537597656},"type":"Container","title":"Cluster Manager","description":"Cluster Manager: The \"allocator\" (e.g., YARN, Kubernetes, or Spark Standalone) that manages resources and decides which machines do what."},{"id":"node-1768387081204","position":{"x":1275.6825561523438,"y":401.58311462402344},"size":{"width":562.68115234375,"height":364.18634033203125},"type":"Container","title":"Executor","pan":{"x":-2543.0732062324178,"y":-1567.0243553749474,"scale":0.18301617063661463}},{"id":"node-1768387081721","position":{"x":1632.4658203125,"y":38.89530944824219},"size":{"width":560.2086181640625,"height":345.6688690185547},"type":"Container","title":"Executor"},{"id":"node-1768387082055","position":{"x":1248.9713592529297,"y":-310.5077381134033},"size":{"width":552.4395751953125,"height":338.85069465637207},"type":"Container","title":"Executor","description":"Executors: The \"workers\" that live on the worker nodes. They execute the tasks assigned by the driver and store data in memory or disk."},{"id":"path-1768387468528","type":"Path","startElement":"node-1768387053759","endElement":"node-1768387067534"},{"id":"path-1768387476110","type":"Path","startElement":"node-1768387067534","endElement":"node-1768387082055"},{"id":"path-1768387478644","type":"Path","startElement":"node-1768387067534","endElement":"node-1768387081721"},{"id":"path-1768387480407","type":"Path","startElement":"node-1768387067534","endElement":"node-1768387081204"}]},{"id":"node-1768388409134","position":{"x":166.90554809570312,"y":533.8389129638672},"size":{"width":229.0255889892578,"height":135.5474090576172},"type":"Container","title":"Spark Core"},{"id":"node-1768388430825","position":{"x":-312.36273193359375,"y":207.39393615722656},"size":{"width":244.0854835510254,"height":172.19094848632812},"type":"Container","title":"Spark SQL"},{"id":"node-1768388535067","position":{"x":25.621116638183594,"y":196.03311157226562},"size":{"width":283.84828186035156,"height":186.39199829101562},"type":"Container","title":"Spark Streaming"},{"id":"node-1768388535701","position":{"x":411.8883361816406,"y":198.8733367919922},"size":{"width":278.16790771484375,"height":177.87135314941406},"type":"Container","title":"MLlib"},{"id":"node-1768388536134","position":{"x":799.5757751464844,"y":197.4532470703125},"size":{"width":255.44622802734375,"height":179.29147338867188},"type":"Container","title":"GraphX"}]}]}}